{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43166ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "import os\n",
    "import cv2 #이미지 읽기용\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c305b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "list = [[0]*4]*100 # 1 x 4 배열을 100개 만듬\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180e2ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 96, 199, 199]\n",
      "[260, 64, 190, 190]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('face.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "for (x,y,w,h) in faces: #좌표 값과 rectangular의 width height를 받게 된다.\n",
    "    # x,y값은 rectangular가 시작하는 지점의 좌표\n",
    "    # x, y값은 좌표값 w,h는 얼굴 높이 너비\n",
    "    # 원본 이미지에 얼굴의 위치를 표시하는 작업을 함.\n",
    "    # for문을 돌리는 이유는 여러 개가 검출 될 수 있기 때문.\n",
    "\n",
    "    list[count][0] = x\n",
    "    list[count][1] = y\n",
    "    list[count][2] = w\n",
    "    list[count][3] = h\n",
    "    print(list[count])\n",
    "    #image 좌표값대로 잘라서 따로 저장하는 부분\n",
    "    img_trim = img[y:y + h,x:x + w]  # trim한 결과를 img_trim에 담는다\n",
    "    cv2.imwrite('target_{}.jpg'.format(count),img_trim) #각 카운터에 맞는 이름으로 저장\n",
    "    \n",
    "    count = count + 1\n",
    "\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780da144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 540, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a9353d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ac6d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#분석 준비\n",
    "image_size=32\n",
    "labels=['neutral', 'fear', 'happy', 'sad', 'angry', 'surprise']\n",
    "analy_image=[]\n",
    "img_count = 0\n",
    "\n",
    "#데이터 전처리\n",
    "for index in faces:\n",
    "    image = cv2.imread(\"target_{}.jpg\".format(img_count)) #이미지 읽기\n",
    "    image = cv2.resize(image, (image_size,image_size)) #이미지 사이즈 편집\n",
    "    image = img_to_array(image) #이미지 배열화\n",
    "    image = np.array(image, dtype=\"float64\") / 255.0\n",
    "    print(image.shape)\n",
    "    analy_image.append(image)\n",
    "    img_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dfe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predict = model.predict(analy_image) #사진 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ee0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 출력\n",
    "label = labels[image_predict[0].argmax()]\n",
    "confidence = image_predict[0][image_predict[0].argmax()]\n",
    "print('{} {:.2f}%'.format(label, confidence * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7559b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f09f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc664452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0059cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9dea07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe4591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94c303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
